import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.utils.data as Data
from torchvision import models
from torchvision import transforms
from torchvision.datasets import ImageFolder
import copy

vgg19 = models.vgg19(pretrained=True)
vgg = vgg19.features
#for p in vgg.named_parameters():
#    if '32' in p[0] or '34' in p[0] or '30' in p[0]:
#       p[1].requires_grad=True
#  else:
#     p[1].requires_grad=False

for p in vgg.parameters():
    p.requires_grad=False

class cnn(nn.Module):
    def __init__(self):
        super(cnn, self).__init__()
        self.conv = vgg
        self.classifier = nn.Sequential(
            nn.Linear(25088, 2048),
            nn.ReLU(),
            nn.Linear(2048,1024),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1024,256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv(x)
        x=x.view(-1,25088)
        x = self.classifier(x)
        return x


trans = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

datadirtrain = r"C:\Users\74019\Desktop\DATATRAIN2.0"
datadirval=r"C:\Users\74019\Desktop\DATATEST2.0"
datatrain = ImageFolder(datadirtrain, transform=trans)
dataval=ImageFolder(datadirval,transform=trans)
datatrainloader = Data.DataLoader(datatrain, batch_size=50, shuffle=True)
datavalloader=Data.DataLoader(dataval,batch_size=1,shuffle=True)


def train_model(model, trainloader, valloader, loss_func, optimizer, num_epoch):

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    trainlossall = []
    trainaccall = []
    vallossall = []
    valaccall = []
    for epoch in range(num_epoch):
        print(f"Epoch{epoch}/{num_epoch - 1}")
        print("*" * 10)
        trainloss = 0.0
        trainacc = 0.0
        trainnum = 0
        valloss = 0.0
        valacc = 0.0
        valnum = 0
        for step, (bx, by) in enumerate(trainloader):
            model.train()
            output = model(bx)
            loss = loss_func(output, by)
            pre_lab = torch.argmax(output, 1)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            trainloss += loss.item() * bx.size(0)
            trainacc += torch.sum(pre_lab.data == by.data)
            trainnum += bx.size(0)
            if step and step % 5 == 0:
                print(f"step: {step} trainloss:{trainloss / trainnum} trainacc:{trainacc / trainnum} ")



        for step,(bx,by) in enumerate(valloader):
            model.eval()
            output = model(bx)
            loss = loss_func(output, by)
            pre_lab = torch.argmax(output, 1)
            valloss += loss.item() * bx.size(0)
            valacc += torch.sum(pre_lab.data == by.data)
            valnum += bx.size(0)

        trainlossall.append(trainloss / trainnum)
        trainaccall.append(trainacc / trainnum)
        vallossall.append(valloss / valnum)
        valaccall.append(valacc / valnum)
        print(
                f"eopoch:{epoch} trainloss:{trainloss / trainnum}  trainacc: {trainacc / trainnum}   valloss:{valloss / valnum}   valacc: {valacc / valnum}")
        if valaccall[-1] > best_acc:
            best_acc = valaccall[-1]
            best_model_wts = copy.deepcopy(model.state_dict())

    process = pd.DataFrame(
            data={"epoch:": range(num_epoch), "trainlossall": trainlossall, "vallossall": vallossall,
                  "trainaccall": trainaccall, "valaccall": valaccall})

    model.load_state_dict(best_model_wts)
    return model,process


mycnn = cnn()
optimizer = torch.optim.Adam(mycnn.parameters(), lr=0.001)
optimizer=torch.optim.SGD(mycnn.parameters(),lr=0.01,momentum=0.9)
loss_func = nn.CrossEntropyLoss()
mycnn,process=train_model(mycnn,datatrainloader,datavalloader,loss_func,optimizer,10)

class IM(ImageFolder):
    def __getitem__(self, item):
        orin=super(IM,self).__getitem__(item)
        path=self.imgs[item][0]
        tup=(orin+(path,))
        return tup

datatest=IM(r"C:\Users\74019\Desktop\DATATEST2",transform=trans)
testloader=Data.DataLoader(datatest,shuffle=True)
valloss=0.0
valacc=0.0
valnum=0
for step, (bx, by, bz) in enumerate(testloader):
    mycnn.eval()
    output = mycnn(bx)
    pre_lab = torch.argmax(output, 1)
    print(f"{by}       {output}  {pre_lab}  {bz}")
    valacc += torch.sum(pre_lab.data == by.data)
    valnum += bx.size(0)
print(valacc/valnum)

